{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Using `nets.py`\n",
    "\n",
    "`nets` is a library of 3D U-Net family of architectures. Although it suffices to use the library without needing to modify `nets.py`, adding further network improvements requires that you modify that file.\n",
    "\n",
    "## Choosing models \n",
    "\n",
    "Below is the table indicating the U-Net architectures available in `nets.py`:\n",
    "\n",
    "| Model | Function | Description |\n",
    "|-------|----------|------------|\n",
    "|U-Net|`unet`| 3D U-Net architecture with kernel sizes of 3x3x3 |\n",
    "|U-Net 2D|`unet2d`| 3D U-Net architecture with kernel sizes of 3x3x1 |\n",
    "|U-Net++|`unetpp`| 3D U-Net++ architecture with kernel sizes of 3x3x3 |\n",
    "|U-Net w/ scSE|`scSEunet`| 3D U-Net architecture with kernel sizes of 3x3x3, and <br>Spatial and Channel-wise Squeeze and Excitation (scSE)<br>[[View paper for scSE](https://arxiv.org/abs/1709.01507)]|\n",
    "|U-Net 2D w/ scSE|`scSEunet2d`|3D U-Net architecture with kernel sizes of 3x3x1, and <br>Spatial and Channel-wise Squeeze and Excitation (scSE)|\n",
    "|U-Net++ w/ scSE|`scSEunetpp`|3D U-Net++ architecture with kernel sizes of 3x3x3, and <br>Spatial and Channel-wise Squeeze and Excitation (scSE)|\n",
    "\n",
    "In order to use the functions listed in the table above, make sure you have imported them from `nets`. Below is an example of importing U-Net++ w/ Squeeze and Excitation blocks (this model is also refered to as GlobalSegNet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nets import scSEunetpp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing models\n",
    "\n",
    "As can be seen in `train.py`, all models takeas parameters `(W, H, D, C)` for width, height, depth, and number of input channels respectively. To complete the example of U-Net++, below is a code for initializing the network:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = scSEunetpp(128, 128, 64, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data\n",
    "\n",
    "All networks in `nets.py` expect a similar input shate of `(N, W, H, D, C_in)` and produces an output of shape `(N, W, H, D, C_out)` where:\n",
    "- `N`: dataset size\n",
    "- `W`: input/output image width\n",
    "- `H`: input/output image height\n",
    "- `D`: input/output image depth\n",
    "- `C_in`: input number of channels\n",
    "- `C_out`: output number of channels\n",
    "\n",
    "For the sake of this tutorial, we will use `numpy` to create a random tensor of that shape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "# Training data\n",
    "X = np.random.rand(10, 128, 128, 64, 1)\n",
    "Y = np.random.rand(10, 128, 128, 64, 6)\n",
    "\n",
    "# Validation data\n",
    "Xv = np.random.rand(10, 128, 128, 64, 1)\n",
    "Yv = np.random.rand(10, 128, 128, 64, 6)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net++ with multiple outputs\n",
    "U-Net++ produces multiple outputs and is deeply supervised. This means that our model expects multiple outputs for each semantic level ([Refer to this paper](https://arxiv.org/abs/1807.10165)). The following code processes `Y` and `Yv` to be used to fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y  = {'out_{}'.format(o):Y  for o in range(len(model.outputs))}\n",
    "Yv = {'out_{}'.format(o):Yv for o in range(len(model.outputs))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a model\n",
    "In order to fit the model, we use `model.fit` function. The most basic way to do so is as follows (for the sake of demonstration, we only run the training for one epoch usin the argument `epochs=1`. In a real-case scenario, use a considerable number of epochs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 10 samples, validate on 10 samples\n 2/10 [=====>........................] - ETA: 22:21 - loss: 5.4099 - out_0_loss: 5.4021 - out_1_loss: 5.4215 - out_2_loss: 5.4197 - out_3_loss: 5.3964 - out_0_dice_coef: 0.6492 - out_1_dice_coef: 0.6561 - out_2_dice_coef: 0.6440 - out_3_dice_coef: 0.6547"
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=1, validation_data=(Xv, Yv), epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoints during training (saving the model)\n",
    "In order to save the model, this code uses a Keras callback during training to save the model with the least loss value for validation data. The callback is defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = tf.keras.callbacks.ModelCheckpoint('model.p5', save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, you can have an **early stopping** condition in order to stop the training if the validation loss does not improve in `n` epochs:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopper = tf.keras.callbacks.EarlyStopping(patience=20, monitor='val_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with `n` being 20 in the above case.\n",
    "\n",
    "## Training with `ModelCheckpoint` and `EarlyStopping`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 10 samples, validate on 10 samples\n10/10 [==============================] - 26s 3s/sample - loss: 5.3777 - out_0_loss: 5.3782 - out_1_loss: 5.3779 - out_2_loss: 5.3771 - out_3_loss: 5.3776 - out_0_dice_coef: 0.6498 - out_1_dice_coef: 0.6480 - out_2_dice_coef: 0.6385 - out_3_dice_coef: 0.6406 - val_loss: 5.3764 - val_out_0_loss: 5.3765 - val_out_1_loss: 5.3764 - val_out_2_loss: 5.3763 - val_out_3_loss: 5.3765 - val_out_0_dice_coef: 0.6498 - val_out_1_dice_coef: 0.6481 - val_out_2_dice_coef: 0.6387 - val_out_3_dice_coef: 0.6404\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f6025d03b50>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "model.fit(X, Y, batch_size=1, validation_data=(Xv, Yv), callbacks=[checkpointer, earlystopper])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations\n",
    "Congratulations! you finished the tutorials, this should be all you need to work this code. Please refer to `train.py` and see how everything is put together."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37764bit3dunetppcondaa47db6f8253649109f561fc4a4537212",
   "display_name": "Python 3.7.7 64-bit ('3dunetpp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}